# Hippius Integration Reference
# SN75 - Decentralized storage for Bittensor subnets

overview:
  what: "Decentralized storage subnet providing S3 and IPFS"
  provides:
    - s3_compatible_buckets
    - ipfs_pinning
    - verifiable_timestamps
    - erasure_coding
    - encryption
    - blockchain_anchored_provenance
  
  key_feature: |
    Every file has verifiable timestamps (last_edited) anchored to 
    Substrate blockchain - proves data provenance without trusted third party

use_cases:
  evaluation_dataset_storage:
    purpose: "store validator test sets with provenance"
    benefit:
      - timestamp_proves_data_existed_before_miner_submission
      - prevents_miners_gaming_historical_data
      - immutable_reference_datasets
    
    code: |
      import asyncio
      from hippius_sdk import HippiusClient
      
      async def store_eval_dataset(dataset_path: str) -> str:
          client = HippiusClient(ipfs_api_url="http://localhost:5001")
          
          # Upload with encryption for private eval sets
          result = await client.upload_file(dataset_path, encrypt=True)
          cid = result["cid"]
          
          # Timestamp is automatically anchored to chain
          # Can later prove this data existed at upload time
          return cid

  miner_submission_artifacts:
    purpose: "miners store artifacts, validators pull from committed location"
    
    IMPORTANT_constraint:
      rule: "Chain commitments rate-limited to 1 per 100 blocks (~20 min)"
      correct: "Commit BUCKET URL to chain, store items in bucket"
      incorrect: "Commit individual CIDs to chain (too slow)"
    
    correct_pattern: |
      # 1. Miner commits bucket location ONCE to chain
      subtensor.set_commitment(wallet, netuid, "hippius://my-bucket")
      
      # 2. Miner stores artifacts to bucket (no chain interaction)
      async def submit_artifact(artifact_path: str) -> dict:
          client = HippiusClient(ipfs_api_url="http://localhost:5001")
          result = await client.erasure_code_file(artifact_path, k=4, m=10)
          # Store CID in bucket index, NOT on chain
          return {"metadata_cid": result["metadata_cid"]}
      
      # 3. Validator reads bucket location from chain, pulls data directly
    
    incorrect_pattern: |
      # DON'T do this - rate limited!
      for artifact in artifacts:
          cid = await client.upload_file(artifact)
          subtensor.set_commitment(wallet, netuid, cid)  # WRONG: 1 per 100 blocks!

  ground_truth_provenance:
    purpose: "prove evaluation data predates miner responses"
    prevents:
      - post_hoc_eval_set_modification
      - timestamp_manipulation
      - validator_collusion_claims
    
    verification: |
      async def verify_dataset_predates_submission(
          dataset_cid: str,
          submission_block: int,
          substrate_url: str = "wss://rpc.hippius.network"
      ) -> bool:
          """Verify dataset was stored before miner submitted."""
          # Dataset timestamp from Hippius chain
          # Compare against Bittensor submission block
          # Cryptographic proof of temporal ordering
          pass

  large_file_distribution:
    purpose: "distribute model weights or datasets to miners"
    benefit:
      - decentralized_delivery
      - no_single_point_of_failure
      - erasure_coding_for_durability

authentication:
  hippius_key:
    creation: |
      # Get key from https://console.hippius.com/dashboard/settings
      hippius account login
      # Enter HIPPIUS_KEY when prompted
      # Optionally encrypt with password
    
    usage_in_code: |
      client = HippiusClient(
          ipfs_api_url="http://localhost:5001",
          hippius_key="hip_your_key_here"
      )

  environment_setup: |
    export IPFS_NODE_URL=http://localhost:5001
    # Or use config:
    hippius config set ipfs.api_url http://localhost:5001
    hippius config set ipfs.local_ipfs true

storage_options:
  ipfs:
    purpose: "content-addressed immutable storage"
    use_when:
      - need_content_deduplication
      - files_referenced_by_hash
      - immutability_required
    
    cli: |
      hippius store dataset.json
      # Returns: CID QmXxx...
      
      hippius download QmXxx... output.json

  s3_compatible:
    purpose: "familiar bucket-based storage"
    use_when:
      - existing_s3_tooling
      - directory_structures
      - streaming_access
    
    endpoint: "https://s3.hippius.com"
    docs: "https://docs.hippius.com/storage/s3/integration"

provenance_patterns:
  timestamp_anchoring:
    mechanism: |
      1. File uploaded to IPFS
      2. CID + timestamp stored on Hippius Substrate chain
      3. Chain provides cryptographic proof of time
    
    verification: |
      # Every file has verifiable last_edited timestamp
      # Anchored to blockchain - tamper-evident
      
      hippius files
      # Shows files with timestamps from chain

  commit_reveal_datasets:
    purpose: "hide eval sets until after miner submission"
    pattern: |
      1. Encrypt dataset, upload to Hippius
      2. Commit encrypted CID hash to Bittensor
      3. After miner submissions, reveal decryption key
      4. Timestamp proves data existed before reveal

encryption:
  purpose: "private datasets and submissions"
  
  keygen: |
    hippius keygen --copy
    # Generates NaCl key, copies to clipboard
  
  usage: |
    # Encrypt on upload
    hippius --encrypt store sensitive_data.json
    
    # Decrypt on download
    hippius --decrypt download QmXxx... output.json
    
    # SDK
    client = HippiusClient(encrypt_by_default=True)
    result = await client.upload_file("data.json")

erasure_coding:
  purpose: "survive node failures"
  when_to_use:
    - large_model_weights
    - critical_datasets
    - long_term_archival
  
  parameters:
    k: "minimum chunks to reconstruct"
    m: "total chunks created"
    redundancy: "can lose (m-k) chunks"
  
  code: |
    # CLI
    hippius erasure-code model.bin --k 4 --m 10
    
    # SDK
    result = await client.erasure_code_file(
        "model.bin",
        k=4,
        m=10,
        chunk_size=2097152  # 2MB chunks
    )
    
    # Reconstruct later
    await client.reconstruct_from_erasure_code(
        metadata_cid=result["metadata_cid"],
        output_file="reconstructed.bin"
    )

validator_integration:
  storing_eval_sets: |
    async def prepare_evaluation_round():
        client = HippiusClient(ipfs_api_url="http://localhost:5001")
        
        # Store encrypted eval set
        result = await client.upload_file(
            "eval_questions.json",
            encrypt=True
        )
        
        # CID is content-addressed - same content = same CID
        # Timestamp proves when stored
        return result["cid"]
  
  verifying_miner_submissions: |
    async def verify_submission_timing(
        miner_cid: str,
        deadline_block: int
    ) -> bool:
        """Check miner submitted before deadline."""
        client = HippiusClient(ipfs_api_url="http://localhost:5001")
        
        # Get file metadata with timestamp
        exists = await client.exists(miner_cid)
        if not exists["exists"]:
            return False
        
        # Timestamp verification against Bittensor blocks
        # Hippius chain timestamp < deadline_block time
        return True

  distributing_tasks: |
    async def distribute_task_batch(tasks: list) -> str:
        """Store tasks for miners to fetch."""
        import json
        
        client = HippiusClient(ipfs_api_url="http://localhost:5001")
        
        # Store as JSON
        with open("tasks.json", "w") as f:
            json.dump(tasks, f)
        
        result = await client.upload_file("tasks.json")
        
        # Publish globally for faster propagation
        await client.ipfs_client.publish_global(result["cid"])
        
        return result["cid"]

miner_integration:
  submitting_artifacts: |
    async def submit_model_weights(weights_path: str) -> str:
        client = HippiusClient(ipfs_api_url="http://localhost:5001")
        
        # Erasure code for durability
        result = await client.erasure_code_file(
            weights_path,
            k=4,
            m=8,
            encrypt=False  # validators need to read
        )
        
        # Commit metadata_cid to Bittensor chain
        return result["metadata_cid"]

cli_quick_reference:
  install: "pip install hippius"
  
  commands:
    store: "hippius store <file>"
    download: "hippius download <cid> <output>"
    exists: "hippius exists <cid>"
    files: "hippius files  # list stored files with timestamps"
    credits: "hippius credits  # check balance"
    erasure_code: "hippius erasure-code <file> --k 4 --m 10"
    reconstruct: "hippius reconstruct <metadata_cid> <output>"

sdk_installation: |
  pip install hippius
  # Or with poetry
  poetry add hippius

best_practices:
  validators:
    - store_eval_sets_before_round_starts
    - use_encryption_for_private_data
    - verify_timestamps_for_submission_ordering
    - erasure_code_critical_datasets
  
  miners:
    - submit_early_for_timestamp_proof
    - use_erasure_coding_for_large_files
    - wait_for_ipfs_propagation: "60 seconds after upload"
  
  provenance:
    - always_verify_chain_timestamps
    - use_commit_reveal_for_sensitive_evals
    - timestamp_proves_temporal_ordering

cost_mitigation:
  - free_credits_for_new_users
  - erasure_coding_vs_full_replication: "1.6x vs 3x storage"
  - batch_uploads_where_possible
